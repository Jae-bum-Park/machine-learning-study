{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data set 구축."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "    keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 픽셀값을 0~255범위에서 0~1사이로 변환한다.\n",
    "#28x28 크기의 2차원배열을 784크기의 1차원 배열로 펼친다.\n",
    "#train_test_split()함수로 data set을 나눈다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled = train_input/255.0\n",
    "train_scaled = train_scaled.reshape(-1,28*28)\n",
    "train_scaled, test_scaled, train_target, test_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 은닉층(hidden layer)만들기.\n",
    "- 은닉층은 입력층과 출력층 사이에 있는 모든 층을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망의 첫번째 층은 input_shape 매개변수로 입력의 크기를 지정해 주어야 한다.\n",
    "#100개의 뉴런을 가지도록 한다.(뉴런의 개수를 정하는데에는 기준이없다.)\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "\n",
    "#신경망의 두번째 층. 뉴런을 10개로 한다.(출력층의 뉴런보다는 많게 만들어야 한다.)\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층 신경망 만들기(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential클래스의 객체를 만들때에는 여러층을 추가하기 위해 리스트로 만들어 전달한다. 출력층은 가장마지막에 둔다.\n",
    "model = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary() 메서드를 호출하여 층에대한 정보를 얻는다.\n",
    "model.summary()\n",
    "#Non-trainable params : train되지 않은 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential 클래스의 생성자 안에 바로 Dense 클래스의 객체를 만들기.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid',input_shape=(784,), name='hidden'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output')\n",
    "], name = 'fashin MNIST model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fashin MNIST model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential 클래스에 add()메서드를 통해 층을 추가하기.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.7608 - accuracy: 0.7579\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4122 - accuracy: 0.8517\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3806 - accuracy: 0.8615\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3576 - accuracy: 0.8727\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2302e891610>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#epochs 몇회 훈련할지 지정.\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten 클래스\n",
    "- Flatten클래스는 입력차원을 모두 일차원으로 펼치는 역할을 한다.\n",
    "- 입력층 바로 뒤에 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "    keras.datasets.fashion_mnist.load_data()\n",
    "train_scaled = train_input/255.0\n",
    "train_scaled, test_scaled, train_target, test_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3099 - accuracy: 0.8886\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2967 - accuracy: 0.8948\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2851 - accuracy: 0.8985\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2855 - accuracy: 0.8999\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2757 - accuracy: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2302eebfdf0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set 성능평가.\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 954us/step - loss: 0.4205 - accuracy: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42053860425949097, 0.8763333559036255]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set 성능평가.\n",
    "model.evaluate(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD 옵티마이저 사용하기.\n",
    "- 옵티마이저 : loss함수의 값을 최소화 하기 위해 최적의 가중치 값을 찾는 알고리즘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD클래스의 momentum 매개변수의 기본값은 0이다. \n",
    "#0보다 큰 값을 지정하면 이전의 Gradient를 가속도처럼 사용하는 momentum optimization을 사용한다.\n",
    "#SGD클래스의 nesterov 매개변수의 기본값은 False이다.\n",
    "#False에서 True로 바꾸면 nesterov momentum optimization을 사용한다.\n",
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#적응적 학습률(adaptive learning rate) : 모델이 최적점에 가까이 갈수록 학습률을 낮추게 하는 방법.\n",
    "#적응적 학습률을 사용하는 대표적 옵티마이저 : Adagrad, RMSprop\n",
    "\n",
    "#adgard\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "#rmsprop\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop, loss='spare_categorical_crossentropy', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam알고리즘.\n",
    "- 모멘텀 최적화(momentum optimization)와 RMSprop의 장점을 접목한 것.\n",
    "- learning_rate 매개변수의 기본값으로 모두 0.001을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 0.6937 - accuracy: 0.7639\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.4072 - accuracy: 0.8540\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.3599 - accuracy: 0.8676\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 0.3336 - accuracy: 0.8783\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 0.3086 - accuracy: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2302f425190>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 524us/step - loss: 0.3345 - accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3344849944114685, 0.8800833225250244]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_scaled,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
